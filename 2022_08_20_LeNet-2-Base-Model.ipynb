{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIz5GR7WkEk6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqMbVNNTUIB3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6je9gGehvNy"
   },
   "outputs": [],
   "source": [
    "GESTURES = [\"g1\",\"g2\",\"g3\",\"g4\",\"g5\",\"g6\",\"g7\"]\n",
    "SAMPLES_PER_GESTURE = 100\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "ONE_HOT_GESTURES = np.eye(NUM_GESTURES) \n",
    "NUM_SENSOR = 6 \n",
    "\n",
    "inputs = [] \n",
    "outputs = [] \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "for g_idx in range(NUM_GESTURES):\n",
    "    g = GESTURES[g_idx]\n",
    "    output = ONE_HOT_GESTURES[g_idx]\n",
    "    df1 = pd.read_csv(\"subject1/\" + g + \".csv\",header = None)\n",
    "    df2 = pd.read_csv(\"subject2/\" + g + \".csv\",header = None)\n",
    "    df3 = pd.read_csv(\"subject3/\" + g + \".csv\",header = None)\n",
    "    df4 = pd.read_csv(\"subject4/\" + g + \".csv\",header = None)\n",
    "    df5 = pd.read_csv(\"subject5/\" + g + \".csv\",header = None)\n",
    "    df6 = pd.read_csv(\"subject6/\" + g + \".csv\",header = None)\n",
    "    df = pd.concat([df1,df2,df3,df4,df6])\n",
    "    df_scaled = scaler.fit_transform(df) \n",
    "    df_scaled_DF = pd.DataFrame(df_scaled)  \n",
    "    df_scaled_DF = df_scaled_DF.dropna()   \n",
    "    num_recordings = int(df_scaled_DF.shape[0] / SAMPLES_PER_GESTURE)\n",
    "\n",
    "    for i in range(num_recordings):\n",
    "        sensorData = df_scaled_DF.iloc[i*SAMPLES_PER_GESTURE:(i+1)*SAMPLES_PER_GESTURE,:]\n",
    "        sensorData_np = np.array(sensorData) \n",
    "        sensorData_np = np.reshape(sensorData_np,SAMPLES_PER_GESTURE*NUM_SENSOR)\n",
    "        inputs.append(sensorData_np)\n",
    "        outputs.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_np = np.array(inputs)\n",
    "outputs_np = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs_np,outputs_np, train_size=0.7, stratify= outputs_np)\n",
    "#X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,stratify= y_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(X_train)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = np.array(y_train)\n",
    "temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSMlPkRw192i",
    "outputId": "efda1599-a867-4b73-c8e1-f71e95ad57a6"
   },
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(600,1)))\n",
    "model.add(tf.keras.layers.Conv1D(filters = 8,activation='relu', kernel_size = 3))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(filters = 16,activation='relu', kernel_size = 5))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu')) \n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) \n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=50, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('base_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvgOEaIb0FBQ"
   },
   "outputs": [],
   "source": [
    "model_accuracy = np.array(history.history['accuracy'])\n",
    "model_val_accuracy = np.array(history.history['val_accuracy'])\n",
    "model_loss = np.array(history.history['loss'])\n",
    "model_val_loss = np.array(history.history['val_loss'])\n",
    "np.savetxt(\"acc.txt\",model_accuracy)\n",
    "np.savetxt(\"val_acc.txt\",model_val_accuracy)\n",
    "np.savetxt(\"loss.txt\",model_loss)\n",
    "np.savetxt(\"val_loss.txt\",model_val_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
